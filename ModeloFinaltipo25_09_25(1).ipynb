{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gT0QnbGnIxQ",
        "outputId": "fd0b10af-5973-4eda-c347-19b264f2ac08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightgbm) (1.16.2)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost\n",
        "!pip install lightgbm\n",
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G07MSsz0RpLh",
        "outputId": "ea6d566c-8ecf-4d5f-ef1b-317b5c7efe1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from lime) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lime) (1.16.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from lime) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.12/dist-packages (from lime) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.12/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2025.9.9)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.18->lime) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.18->lime) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=8c051dc4dc0e4aefea0601414e69365975d7ca803fde0bd1a9e47a7882cb32c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/5d/0e/4b4fff9a47468fed5633211fb3b76d1db43fe806a17fb7486a\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Codigo para compartir**"
      ],
      "metadata": {
        "id": "7Eb-XjIvFSU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Predicción con Varios Modelos + SHAP y LIME\n",
        "# ============================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
        "\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "\n",
        "# =======================\n",
        "# 1. Cargar base de datos\n",
        "# =======================\n",
        "file_path = \"nueva_base_con_rezagosfinal.xlsx\"\n",
        "df = pd.read_excel(file_path, sheet_name=\"Sheet1\")\n",
        "\n",
        "# Eliminar filas con valores nulos\n",
        "df = df.dropna()\n",
        "\n",
        "# ==============================\n",
        "# 2. Seleccionar variables\n",
        "# ==============================\n",
        "y = df[\"ITCRM\"]\n",
        "\n",
        "# Eliminar columna dependiente + columnas tipo datetime\n",
        "X = df.drop(columns=[\"ITCRM\"])\n",
        "X = X.select_dtypes(exclude=[\"datetime\", \"datetime64[ns]\"])\n",
        "\n",
        "# ==============================\n",
        "# 3. Separar en train y test\n",
        "# ==============================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, shuffle=False\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# 4. Definir modelos\n",
        "# ==============================\n",
        "modelos = {\n",
        "    \"RandomForest\": RandomForestRegressor(n_estimators=300, max_depth=10, random_state=42),\n",
        "    \"XGBoost\": xgb.XGBRegressor(n_estimators=300, max_depth=6, learning_rate=0.1, random_state=42),\n",
        "    \"LightGBM\": lgb.LGBMRegressor(n_estimators=300, max_depth=10, learning_rate=0.1, random_state=42),\n",
        "    \"CatBoost\": cb.CatBoostRegressor(n_estimators=300, depth=8, learning_rate=0.1, random_state=42, verbose=0)\n",
        "}\n",
        "\n",
        "resultados = {}\n",
        "predicciones = pd.DataFrame(index=y_test.index)\n",
        "\n",
        "# ==============================\n",
        "# 5. Entrenamiento y evaluación\n",
        "# ==============================\n",
        "for nombre, modelo in modelos.items():\n",
        "    print(f\"\\nEntrenando {nombre}...\")\n",
        "    modelo.fit(X_train, y_train)\n",
        "    y_pred = modelo.predict(X_test)\n",
        "\n",
        "    # Guardar predicciones\n",
        "    predicciones[nombre] = y_pred\n",
        "\n",
        "    # Evaluación\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    resultados[nombre] = {\n",
        "        \"MAE\": mae,\n",
        "        \"RMSE\": rmse,\n",
        "        \"MAPE\": mape,\n",
        "        \"R2\": r2\n",
        "    }\n",
        "\n",
        "    print(f\"{nombre} -> MAE: {mae:.4f}, RMSE: {rmse:.4f}, MAPE: {mape:.4f}, R²: {r2:.4f}\")\n",
        "\n",
        "# ==============================\n",
        "# 6. Importancia de variables\n",
        "# ==============================\n",
        "importancias = pd.DataFrame()\n",
        "\n",
        "for nombre, modelo in modelos.items():\n",
        "    try:\n",
        "        if nombre == \"CatBoost\":\n",
        "            imp = modelo.get_feature_importance()\n",
        "        else:\n",
        "            imp = modelo.feature_importances_\n",
        "        temp = pd.DataFrame({\n",
        "            \"Variable\": X.columns,\n",
        "            \"Importancia\": imp,\n",
        "            \"Modelo\": nombre\n",
        "        })\n",
        "        importancias = pd.concat([importancias, temp], axis=0)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "# ==============================\n",
        "# 7. Intervalo de confianza CatBoost\n",
        "# ==============================\n",
        "if \"CatBoost\" in modelos:\n",
        "    y_pred_cat = predicciones[\"CatBoost\"].values\n",
        "    residuales = y_test.values - y_pred_cat\n",
        "    sigma = np.std(residuales)\n",
        "\n",
        "    ic_inf = y_pred_cat - 1.96 * sigma\n",
        "    ic_sup = y_pred_cat + 1.96 * sigma\n",
        "\n",
        "    predicciones[\"CatBoost_IC_inf\"] = ic_inf\n",
        "    predicciones[\"CatBoost_IC_sup\"] = ic_sup\n",
        "\n",
        "    print(f\"\\nIntervalo de confianza (aprox) CatBoost con σ={sigma:.4f}\")\n",
        "\n",
        "# ==============================\n",
        "# 8. Gráfico conjunto\n",
        "# ==============================\n",
        "plt.figure(figsize=(14,7))\n",
        "plt.plot(y_test.values, label=\"Real\", marker=\"o\", linewidth=2)\n",
        "\n",
        "for nombre in modelos.keys():\n",
        "    plt.plot(predicciones[nombre].values, label=nombre, linestyle=\"--\")\n",
        "\n",
        "plt.title(\"Comparación de Modelos - Predicción ITCRM\")\n",
        "plt.xlabel(\"Observaciones\")\n",
        "plt.ylabel(\"ITCRM\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ==============================\n",
        "# 9. Importancia de variables (gráfico)\n",
        "# ==============================\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.barplot(data=importancias, x=\"Importancia\", y=\"Variable\", hue=\"Modelo\")\n",
        "plt.title(\"Importancia de Variables por Modelo\")\n",
        "plt.show()\n",
        "\n",
        "# ==============================\n",
        "# 10. Seleccionar mejor modelo según R²\n",
        "# ==============================\n",
        "resultados_df = pd.DataFrame(resultados).T\n",
        "mejor_modelo_nombre = resultados_df[\"R2\"].idxmax()\n",
        "mejor_modelo = modelos[mejor_modelo_nombre]\n",
        "\n",
        "print(f\"\\nMejor modelo según R²: {mejor_modelo_nombre}\")\n",
        "\n",
        "# ==============================\n",
        "# 11. Interpretabilidad con SHAP\n",
        "# ==============================\n",
        "import shap\n",
        "interpretabilidad = {}\n",
        "\n",
        "try:\n",
        "    if mejor_modelo_nombre == \"XGBoost\":\n",
        "        explainer = shap.TreeExplainer(mejor_modelo)\n",
        "        shap_values = explainer.shap_values(X_test)\n",
        "    elif mejor_modelo_nombre == \"LightGBM\":\n",
        "        explainer = shap.TreeExplainer(mejor_modelo.booster_)\n",
        "        shap_values = explainer.shap_values(X_test)\n",
        "    elif mejor_modelo_nombre == \"CatBoost\":\n",
        "        explainer = shap.TreeExplainer(mejor_modelo)\n",
        "        shap_values = explainer.shap_values(X_test)\n",
        "    elif mejor_modelo_nombre == \"RandomForest\":\n",
        "        explainer = shap.TreeExplainer(mejor_modelo)\n",
        "        shap_values = explainer.shap_values(X_test)\n",
        "    else:\n",
        "        shap_values = None\n",
        "\n",
        "    if shap_values is not None:\n",
        "        shap_importancia = pd.DataFrame({\n",
        "            \"Variable\": X.columns,\n",
        "            \"SHAP_Importancia\": np.abs(shap_values).mean(axis=0)\n",
        "        }).sort_values(by=\"SHAP_Importancia\", ascending=False)\n",
        "\n",
        "        interpretabilidad[\"SHAP\"] = shap_importancia\n",
        "\n",
        "        shap.summary_plot(shap_values, X_test, plot_type=\"bar\", show=False)\n",
        "        plt.title(f\"SHAP Importancia Global - {mejor_modelo_nombre}\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"shap_summary.png\")\n",
        "        plt.close()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error con SHAP: {e}\")\n",
        "\n",
        "# ==============================\n",
        "# 12. Interpretabilidad con LIME\n",
        "# ==============================\n",
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "\n",
        "try:\n",
        "    lime_explainer = LimeTabularExplainer(\n",
        "        training_data=np.array(X_train),\n",
        "        feature_names=X.columns,\n",
        "        mode=\"regression\"\n",
        "    )\n",
        "\n",
        "    lime_resultados = []\n",
        "    for i in range(min(5, len(X_test))):  # explicamos 5 casos\n",
        "        exp = lime_explainer.explain_instance(\n",
        "            data_row=X_test.iloc[i].values,\n",
        "            predict_fn=mejor_modelo.predict\n",
        "        )\n",
        "        temp = pd.DataFrame(exp.as_list(), columns=[\"Variable\", \"Efecto\"])\n",
        "        temp[\"Observacion\"] = i\n",
        "        lime_resultados.append(temp)\n",
        "\n",
        "    lime_df = pd.concat(lime_resultados, axis=0)\n",
        "    interpretabilidad[\"LIME\"] = lime_df\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error con LIME: {e}\")\n",
        "\n",
        "# ==============================\n",
        "# 13. Guardar resultados en Excel (final)\n",
        "# ==============================\n",
        "with pd.ExcelWriter(\"resultados_modelos.xlsx\") as writer:\n",
        "    # Métricas\n",
        "    resultados_df.to_excel(writer, sheet_name=\"Metricas\")\n",
        "\n",
        "    # Predicciones + Intervalo CatBoost\n",
        "    salida = pd.concat([y_test.reset_index(drop=True), predicciones.reset_index(drop=True)], axis=1)\n",
        "    salida.rename(columns={\"ITCRM\": \"Real\"}, inplace=True)\n",
        "    salida.to_excel(writer, sheet_name=\"Predicciones\", index=False)\n",
        "\n",
        "    # Importancia de variables\n",
        "    importancias.to_excel(writer, sheet_name=\"Importancias\", index=False)\n",
        "\n",
        "    # SHAP\n",
        "    if \"SHAP\" in interpretabilidad:\n",
        "        interpretabilidad[\"SHAP\"].to_excel(writer, sheet_name=\"SHAP\", index=False)\n",
        "\n",
        "    # LIME\n",
        "    if \"LIME\" in interpretabilidad:\n",
        "        interpretabilidad[\"LIME\"].to_excel(writer, sheet_name=\"LIME\", index=False)\n",
        "\n",
        "print(\"\\nResultados guardados en 'resultados_modelos.xlsx' con SHAP y LIME para el mejor modelo\")\n"
      ],
      "metadata": {
        "id": "NZCH-ETiFRQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
        "\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "import shap\n",
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "\n",
        "# =======================\n",
        "# 1. Cargar base de datos\n",
        "# =======================\n",
        "file_path = \"nueva_base_con_rezagosfinal.xlsx\"\n",
        "df = pd.read_excel(file_path, sheet_name=\"Sheet1\")\n",
        "\n",
        "# Eliminar filas con valores nulos\n",
        "df = df.dropna()\n",
        "\n",
        "# ==============================\n",
        "# 2. Seleccionar variables\n",
        "# ==============================\n",
        "y = df[\"ITCRM\"]\n",
        "\n",
        "# Eliminar columna dependiente + columnas tipo datetime\n",
        "X = df.drop(columns=[\"ITCRM\"])\n",
        "X = X.select_dtypes(exclude=[\"datetime\", \"datetime64[ns]\"])\n",
        "\n",
        "# ==============================\n",
        "# 3. Separar en train y test\n",
        "# ==============================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, shuffle=False\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# 4. Definir modelos\n",
        "# ==============================\n",
        "modelos = {\n",
        "    \"RandomForest\": RandomForestRegressor(n_estimators=300, max_depth=10, random_state=42),\n",
        "    \"XGBoost\": xgb.XGBRegressor(n_estimators=300, max_depth=6, learning_rate=0.1, random_state=42),\n",
        "    \"LightGBM\": lgb.LGBMRegressor(n_estimators=300, max_depth=10, learning_rate=0.1, random_state=42),\n",
        "    \"CatBoost\": cb.CatBoostRegressor(n_estimators=300, depth=8, learning_rate=0.1, random_state=42, verbose=0)\n",
        "}\n",
        "\n",
        "resultados = {}\n",
        "predicciones = pd.DataFrame(index=y_test.index)\n",
        "\n",
        "# ==============================\n",
        "# 5. Entrenamiento y evaluación\n",
        "# ==============================\n",
        "for nombre, modelo in modelos.items():\n",
        "    print(f\"\\nEntrenando {nombre}...\")\n",
        "    modelo.fit(X_train, y_train)\n",
        "    y_pred = modelo.predict(X_test)\n",
        "\n",
        "    # Guardar predicciones\n",
        "    predicciones[nombre] = y_pred\n",
        "\n",
        "    # Evaluación\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    resultados[nombre] = {\n",
        "        \"MAE\": mae,\n",
        "        \"RMSE\": rmse,\n",
        "        \"MAPE\": mape,\n",
        "        \"R2\": r2\n",
        "    }\n",
        "\n",
        "    print(f\"{nombre} -> MAE: {mae:.4f}, RMSE: {rmse:.4f}, MAPE: {mape:.4f}, R²: {r2:.4f}\")\n",
        "\n",
        "# ==============================\n",
        "# 6. Importancia de variables\n",
        "# ==============================\n",
        "importancias = pd.DataFrame()\n",
        "\n",
        "for nombre, modelo in modelos.items():\n",
        "    try:\n",
        "        if nombre == \"CatBoost\":\n",
        "            imp = modelo.get_feature_importance()\n",
        "        else:\n",
        "            imp = modelo.feature_importances_\n",
        "        temp = pd.DataFrame({\n",
        "            \"Variable\": X.columns,\n",
        "            \"Importancia\": imp,\n",
        "            \"Modelo\": nombre\n",
        "        })\n",
        "        importancias = pd.concat([importancias, temp], axis=0)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "# ==============================\n",
        "# 7. Intervalo de confianza CatBoost\n",
        "# ==============================\n",
        "if \"CatBoost\" in modelos:\n",
        "    y_pred_cat = predicciones[\"CatBoost\"].values\n",
        "    residuales = y_test.values - y_pred_cat\n",
        "    sigma = np.std(residuales)\n",
        "\n",
        "    ic_inf = y_pred_cat - 1.96 * sigma\n",
        "    ic_sup = y_pred_cat + 1.96 * sigma\n",
        "\n",
        "    predicciones[\"CatBoost_IC_inf\"] = ic_inf\n",
        "    predicciones[\"CatBoost_IC_sup\"] = ic_sup\n",
        "\n",
        "    print(f\"\\nIntervalo de confianza (aprox) CatBoost con σ={sigma:.4f}\")\n",
        "\n",
        "# ==============================\n",
        "# 8. Gráfico conjunto\n",
        "# ==============================\n",
        "plt.figure(figsize=(14,7))\n",
        "plt.plot(y_test.values, label=\"Real\", marker=\"o\", linewidth=2)\n",
        "\n",
        "for nombre in modelos.keys():\n",
        "    plt.plot(predicciones[nombre].values, label=nombre, linestyle=\"--\")\n",
        "\n",
        "plt.title(\"Comparación de Modelos - Predicción ITCRM\")\n",
        "plt.xlabel(\"Observaciones\")\n",
        "plt.ylabel(\"ITCRM\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ==============================\n",
        "# 9. Importancia de variables (gráfico)\n",
        "# ==============================\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.barplot(data=importancias, x=\"Importancia\", y=\"Variable\", hue=\"Modelo\")\n",
        "plt.title(\"Importancia de Variables por Modelo\")\n",
        "plt.show()\n",
        "\n",
        "# ==============================\n",
        "# 10. Seleccionar mejor modelo según R²\n",
        "# ==============================\n",
        "resultados_df = pd.DataFrame(resultados).T\n",
        "mejor_modelo_nombre = resultados_df[\"R2\"].idxmax()\n",
        "mejor_modelo = modelos[mejor_modelo_nombre]\n",
        "\n",
        "print(f\"\\nMejor modelo según R²: {mejor_modelo_nombre}\")\n",
        "\n",
        "# ==============================\n",
        "# 11. Interpretabilidad con SHAP (para todos los modelos)\n",
        "# ==============================\n",
        "interpretabilidad = {}\n",
        "shap_importancias = pd.DataFrame()\n",
        "\n",
        "for nombre, modelo in modelos.items():\n",
        "    try:\n",
        "        if nombre == \"XGBoost\":\n",
        "            explainer = shap.TreeExplainer(modelo)\n",
        "            shap_values = explainer.shap_values(X_test)\n",
        "        elif nombre == \"LightGBM\":\n",
        "            explainer = shap.TreeExplainer(modelo.booster_)\n",
        "            shap_values = explainer.shap_values(X_test)\n",
        "        elif nombre == \"CatBoost\":\n",
        "            explainer = shap.TreeExplainer(modelo)\n",
        "            shap_values = explainer.shap_values(X_test)\n",
        "        elif nombre == \"RandomForest\":\n",
        "            explainer = shap.TreeExplainer(modelo)\n",
        "            shap_values = explainer.shap_values(X_test)\n",
        "        else:\n",
        "            shap_values = None\n",
        "\n",
        "        if shap_values is not None:\n",
        "            shap_importancia = pd.DataFrame({\n",
        "                \"Variable\": X.columns,\n",
        "                \"SHAP_Importancia\": np.abs(shap_values).mean(axis=0),\n",
        "                \"Modelo\": nombre\n",
        "            }).sort_values(by=\"SHAP_Importancia\", ascending=False)\n",
        "\n",
        "            shap_importancias = pd.concat([shap_importancias, shap_importancia], axis=0)\n",
        "\n",
        "            # Gráfico SHAP\n",
        "            shap.summary_plot(shap_values, X_test, plot_type=\"bar\", show=False)\n",
        "            plt.title(f\"SHAP Importancia Global - {nombre}\")\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f\"shap_summary_{nombre}.png\")\n",
        "            plt.close()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error con SHAP para {nombre}: {e}\")\n",
        "\n",
        "interpretabilidad[\"SHAP\"] = shap_importancias\n",
        "\n",
        "# ==============================\n",
        "# 12. Interpretabilidad con LIME (para todos los modelos)\n",
        "# ==============================\n",
        "try:\n",
        "    lime_explainer = LimeTabularExplainer(\n",
        "        training_data=np.array(X_train),\n",
        "        feature_names=X.columns,\n",
        "        mode=\"regression\"\n",
        "    )\n",
        "\n",
        "    lime_resultados = []\n",
        "    for nombre, modelo in modelos.items():\n",
        "        for i in range(min(5, len(X_test))):  # explicamos 5 casos por modelo\n",
        "            exp = lime_explainer.explain_instance(\n",
        "                data_row=X_test.iloc[i].values,\n",
        "                predict_fn=modelo.predict\n",
        "            )\n",
        "            temp = pd.DataFrame(exp.as_list(), columns=[\"Variable\", \"Efecto\"])\n",
        "            temp[\"Observacion\"] = i\n",
        "            temp[\"Modelo\"] = nombre\n",
        "            lime_resultados.append(temp)\n",
        "\n",
        "            # Gráfico LIME\n",
        "            fig = exp.as_pyplot_figure()\n",
        "            plt.title(f\"LIME Explicación para {nombre} - Observación {i+1}\")\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f\"lime_{nombre}_obs{i+1}.png\")\n",
        "            plt.close()\n",
        "\n",
        "    lime_df = pd.concat(lime_resultados, axis=0)\n",
        "    interpretabilidad[\"LIME\"] = lime_df\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error con LIME: {e}\")\n",
        "\n",
        "# ==============================\n",
        "# 13. Guardar resultados en Excel (final)\n",
        "# ==============================\n",
        "with pd.ExcelWriter(\"resultados_modelos.xlsx\") as writer:\n",
        "    # Métricas\n",
        "    resultados_df.to_excel(writer, sheet_name=\"Metricas\")\n",
        "\n",
        "    # Predicciones + Intervalo CatBoost\n",
        "    salida = pd.concat([y_test.reset_index(drop=True), predicciones.reset_index(drop=True)], axis=1)\n",
        "    salida.rename(columns={\"ITCRM\": \"Real\"}, inplace=True)\n",
        "    salida.to_excel(writer, sheet_name=\"Predicciones\", index=False)\n",
        "\n",
        "    # Importancia de variables\n",
        "    importancias.to_excel(writer, sheet_name=\"Importancias\", index=False)\n",
        "\n",
        "    # SHAP\n",
        "    if \"SHAP\" in interpretabilidad:\n",
        "        interpretabilidad[\"SHAP\"].to_excel(writer, sheet_name=\"SHAP\", index=False)\n",
        "\n",
        "    # LIME\n",
        "    if \"LIME\" in interpretabilidad:\n",
        "        interpretabilidad[\"LIME\"].to_excel(writer, sheet_name=\"LIME\", index=False)\n",
        "\n",
        "print(\"\\nResultados guardados en 'resultados_modelos.xlsx' con SHAP y LIME para todos los modelos, incluyendo gráficos guardados como PNG.\")"
      ],
      "metadata": {
        "id": "aYuKkbAAxMrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#########################################################################################"
      ],
      "metadata": {
        "id": "f6vkmiOkmmTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# VECM con train-test split, pronósticos y métricas\n",
        "# ===========================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from statsmodels.tsa.vector_ar.vecm import coint_johansen, VECM\n",
        "\n",
        "# ===========================\n",
        "# 1. Cargar y preparar datos\n",
        "# ===========================\n",
        "df = pd.read_excel(\"baseVECMfinal.xlsx\")\n",
        "\n",
        "tcr = \"ITCER\"\n",
        "fundamentales = [\n",
        "    \"IPC\", \"energia\", \"agua\", \"gasliquido\",\n",
        "    \"X\", \"M\", \"RIN\",\n",
        "    \"activa\", \"pasivaahorro\", \"pasivafijo\", \"libor3\", \"FEDFUNDS\",\n",
        "    \"EGRESOSCORRIENTES\", \"INGRESOSCORRIENTES\", \"EGRESOSCAPITAL\", \"INGRESOSCAPITAL\",\n",
        "    \"Oro\", \"Petroleo1\", \"Zinc\", \"Plata\", \"Estano\",\n",
        "    \"temperatura\", \"precipitation\", \"drought\"\n",
        "]\n",
        "\n",
        "model_df = df[[tcr] + fundamentales].dropna()\n",
        "\n",
        "# Variables que van en log\n",
        "log_vars = [\"ITCER\",\"IPC\",\"energia\",\"agua\",\"gasliquido\",\"X\",\"M\",\"RIN\",\n",
        "            \"Oro\",\"Petroleo1\",\"Zinc\",\"Plata\",\"Estano\"]\n",
        "\n",
        "for var in log_vars:\n",
        "    model_df[\"ln_\" + var] = np.log(model_df[var])\n",
        "\n",
        "# Dataset final\n",
        "Y = model_df[[\"ln_ITCER\",\"ln_IPC\",\"ln_X\",\"ln_M\",\"ln_RIN\",\"ln_Oro\",\"ln_Petroleo1\",\n",
        "              \"ln_Zinc\",\"ln_Plata\",\"ln_Estano\",\"activa\",\"pasivaahorro\",\"pasivafijo\",\n",
        "              \"libor3\",\"FEDFUNDS\",\"EGRESOSCORRIENTES\",\"INGRESOSCORRIENTES\",\n",
        "              \"EGRESOSCAPITAL\",\"INGRESOSCAPITAL\",\"temperatura\",\"precipitation\",\"drought\"]]\n",
        "\n",
        "# ===========================\n",
        "# 2. Train-test split\n",
        "# ===========================\n",
        "train_size = int(len(Y) * 0.8)\n",
        "train, test = Y.iloc[:train_size], Y.iloc[train_size:]\n",
        "\n",
        "# ===========================\n",
        "# 3. Prueba de cointegración en train\n",
        "# ===========================\n",
        "johansen_test = coint_johansen(train, det_order=0, k_ar_diff=2)\n",
        "print(\"Trace test:\", johansen_test.lr1)\n",
        "print(\"Critical values:\", johansen_test.cvt)\n",
        "\n",
        "# ===========================\n",
        "# 4. Estimación VECM en train\n",
        "# ===========================\n",
        "vecm = VECM(train, k_ar_diff=2, coint_rank=1, deterministic=\"co\")\n",
        "vecm_res = vecm.fit()\n",
        "print(vecm_res.summary())\n",
        "\n",
        "# ===========================\n",
        "# 5. Pronósticos\n",
        "# ===========================\n",
        "# Pronóstico en horizonte de test\n",
        "n_test = len(test)\n",
        "forecast_test = vecm_res.predict(steps=n_test)\n",
        "forecast_test_df = pd.DataFrame(forecast_test,\n",
        "                                index=test.index,\n",
        "                                columns=Y.columns)\n",
        "\n",
        "# Pronóstico extendido 78 pasos adelante\n",
        "forecast_78 = vecm_res.predict(steps=78)\n",
        "forecast_78_df = pd.DataFrame(forecast_78,\n",
        "                              columns=Y.columns)\n",
        "\n",
        "# ===========================\n",
        "# 6. Guardar en Excel\n",
        "# ===========================\n",
        "with pd.ExcelWriter(\"pronosticos_VECM.xlsx\") as writer:\n",
        "    forecast_test_df.to_excel(writer, sheet_name=\"Forecast_Test\")\n",
        "    forecast_78_df.to_excel(writer, sheet_name=\"Forecast_78\")\n",
        "\n",
        "# ===========================\n",
        "# 7. Métricas en variable clave (ln_ITCER)\n",
        "# ===========================\n",
        "aligned = pd.concat([test[\"ln_ITCER\"], forecast_test_df[\"ln_ITCER\"]], axis=1).dropna()\n",
        "aligned.columns = [\"y_true\", \"y_pred\"]\n",
        "\n",
        "y_true = aligned[\"y_true\"].values\n",
        "y_pred = aligned[\"y_pred\"].values\n",
        "\n",
        "# Métricas\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "rmse = np.sqrt(mse)  # corregido\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "\n",
        "with np.errstate(divide='ignore', invalid='ignore'):\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / y_true))\n",
        "\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"RMSE: {rmse:.6f}\")\n",
        "print(f\"MSE: {mse:.6f}\")\n",
        "print(f\"MAE: {mae:.6f}\")\n",
        "print(f\"MAPE: {mape*100:.4f}%\")\n",
        "\n",
        "# ===========================\n",
        "# 8. Gráfico comparativo\n",
        "# ===========================\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(train.index, train[\"ln_ITCER\"], label=\"Train\", color=\"blue\")\n",
        "plt.plot(aligned.index, aligned[\"y_true\"], label=\"Test Real\", color=\"black\")\n",
        "plt.plot(aligned.index, aligned[\"y_pred\"], label=\"Pronóstico\", linestyle=\"--\", color=\"red\")\n",
        "plt.title(\"Pronóstico VECM vs Valores Reales (ln_ITCER)\")\n",
        "plt.xlabel(\"Tiempo\")\n",
        "plt.ylabel(\"ln_ITCER\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0HobbvuV93hQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# ECM (Regresión Lineal) con Train-Test, Pronósticos y Métricas\n",
        "# ===========================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# ===========================\n",
        "# 1. Cargar y preparar datos\n",
        "# ===========================\n",
        "df = pd.read_excel(\"baseVECMfinal.xlsx\")\n",
        "\n",
        "tcr = \"ITCER\"\n",
        "fundamentales = [\n",
        "    \"IPC\", \"energia\", \"agua\", \"gasliquido\",\n",
        "    \"X\", \"M\", \"RIN\",\n",
        "    \"activa\", \"pasivaahorro\", \"pasivafijo\", \"libor3\", \"FEDFUNDS\",\n",
        "    \"EGRESOSCORRIENTES\", \"INGRESOSCORRIENTES\", \"EGRESOSCAPITAL\", \"INGRESOSCAPITAL\",\n",
        "    \"Oro\", \"Petroleo1\", \"Zinc\", \"Plata\", \"Estano\",\n",
        "    \"temperatura\", \"precipitation\", \"drought\"\n",
        "]\n",
        "\n",
        "model_df = df[[tcr] + fundamentales].dropna()\n",
        "\n",
        "# Variables en log\n",
        "log_vars = [\"ITCER\",\"IPC\",\"energia\",\"agua\",\"gasliquido\",\"X\",\"M\",\"RIN\",\n",
        "            \"Oro\",\"Petroleo1\",\"Zinc\",\"Plata\",\"Estano\"]\n",
        "\n",
        "for var in log_vars:\n",
        "    model_df[\"ln_\" + var] = np.log(model_df[var])\n",
        "\n",
        "# Dataset: dependiente + regresores\n",
        "Y = model_df[\"ln_ITCER\"]\n",
        "X = model_df.drop(columns=[tcr, \"ITCER\", \"ln_ITCER\"])  # quitamos duplicados\n",
        "\n",
        "# ===========================\n",
        "# 2. Train-test split\n",
        "# ===========================\n",
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]\n",
        "Y_train, Y_test = Y.iloc[:train_size], Y.iloc[train_size:]\n",
        "\n",
        "# ===========================\n",
        "# 3. Estimación de regresión lineal\n",
        "# ===========================\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# ===========================\n",
        "# 4. Pronósticos\n",
        "# ===========================\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "# ===========================\n",
        "# 5. Métricas\n",
        "# ===========================\n",
        "mse = mean_squared_error(Y_test, Y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(Y_test, Y_pred)\n",
        "r2 = r2_score(Y_test, Y_pred)\n",
        "\n",
        "with np.errstate(divide='ignore', invalid='ignore'):\n",
        "    mape = np.mean(np.abs((Y_test.values - Y_pred) / Y_test.values))\n",
        "\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"RMSE: {rmse:.6f}\")\n",
        "print(f\"MSE: {mse:.6f}\")\n",
        "print(f\"MAE: {mae:.6f}\")\n",
        "print(f\"MAPE: {mape*100:.4f}%\")\n",
        "\n",
        "# ===========================\n",
        "# 6. Guardar en Excel\n",
        "# ===========================\n",
        "results_df = pd.DataFrame({\n",
        "    \"Real\": Y_test.values,\n",
        "    \"Pronosticado\": Y_pred\n",
        "}, index=Y_test.index)\n",
        "\n",
        "with pd.ExcelWriter(\"pronosticos_ECM.xlsx\") as writer:\n",
        "    results_df.to_excel(writer, sheet_name=\"Forecast_Test\")\n",
        "    pd.DataFrame({\n",
        "        \"R2\":[r2], \"RMSE\":[rmse], \"MSE\":[mse], \"MAE\":[mae], \"MAPE\":[mape]\n",
        "    }).to_excel(writer, sheet_name=\"Metrics\", index=False)\n",
        "\n",
        "# ===========================\n",
        "# 7. Gráfico comparativo\n",
        "# ===========================\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(Y_train.index, Y_train, label=\"Train\", color=\"blue\")\n",
        "plt.plot(Y_test.index, Y_test, label=\"Test Real\", color=\"black\")\n",
        "plt.plot(Y_test.index, Y_pred, label=\"Pronóstico\", linestyle=\"--\", color=\"red\")\n",
        "plt.title(\"Regresión Lineal (ECM) - Pronóstico vs Real (ln_ITCER)\")\n",
        "plt.xlabel(\"Tiempo\")\n",
        "plt.ylabel(\"ln_ITCER\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pheAkpuL_ANQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}